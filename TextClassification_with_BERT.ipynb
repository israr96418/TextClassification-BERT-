{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Install necessary libraries**\n",
        "here I already install required libraries"
      ],
      "metadata": {
        "id": "LMhbSt8NlEOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step1: Import the necessary libraries**"
      ],
      "metadata": {
        "id": "eVqFr94Flctj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer , BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "I2dGWlutlQaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step2: Import the IMDB(movie review dataaset) dataset and process it**"
      ],
      "metadata": {
        "id": "COQKAC1RmX1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_imdb_dataset(data_file):\n",
        "  movie_frame = pd.read_csv(data_file)\n",
        "  texts = movie_frame['review'].tolist()\n",
        "  labels = [1 if sentiment == 'positive' else 0  for sentiment in movie_frame['sentiment'].tolist()]\n",
        "  return texts , labels"
      ],
      "metadata": {
        "id": "wWY-PniqmLrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/IMDB Dataset.csv\"\n",
        "texts, labels = load_imdb_dataset(data_file)\n"
      ],
      "metadata": {
        "id": "Hlt1G9SHm53y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "tnkB-JK5m56X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239b9523-0196-4e9b-9bfb-7eb52133c8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create a custom dataset class for text classification**\n",
        "- this class help us to organize movie review and their sentiment for our BERt model <br>\n",
        "- this class also take care of tokenizing the input text <br>\n",
        "- handling the sequence length of text\n",
        "- and providing a neat package with input IDs\n",
        "- attention masks and labels for our model to learn from"
      ],
      "metadata": {
        "id": "wG1qDLpmvm7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "  def __len__(self):\n",
        "        return len(self.texts)\n",
        "  def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"
      ],
      "metadata": {
        "id": "Bgf8ZqkPm582"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build our customer BERT model classifer**\n",
        "- in this step create customer BERT model classifer , on the top of base BERT model, which is greate understanding of text.\n",
        "- then we will add dropout layer ---> to keeps things in chunks\n",
        "- after adding dropout layer , then add linear layer --> which help us to classify text"
      ],
      "metadata": {
        "id": "j5zlVvR60ejR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_classes):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dD4cfbYam5-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train function**\n",
        "The train() function takes the model, data loader, optimizer, scheduler, and device as its trainees."
      ],
      "metadata": {
        "id": "MMQaCXWJ4FbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "id": "2azJOK_cm6BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build our model evalation model**\n"
      ],
      "metadata": {
        "id": "_u3qvOep56b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
      ],
      "metadata": {
        "id": "B9aXMX7Cm6DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build our model prediction method**\n",
        "- The predict_sentiment() function acts as our evaluation method.\n",
        "- For each batch, it gets the input IDs, attention masks, and labels and feeds them to the model.\n",
        "- The model then gives its best predictions, which are compared to the actual labels.\n",
        "\n",
        "Finally, the function calculates the accuracy score and a classification report to let us know how well the model did in understanding movie reviewsâ€™ sentiments"
      ],
      "metadata": {
        "id": "sHOLV4tZ6GYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "    return \"positive\" if preds.item() == 1 else \"negative\"\n"
      ],
      "metadata": {
        "id": "DPU165QMm6Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define our model paramters**\n",
        "- Here we are going to define essentail parameter of our model to finetune the BERTClassifier\n",
        "- Including the BERT model name, number of classes, maximum input sequence length, batch size, number of training epochs, and learning rate, to help the model effectively understand movie reviews and their sentiment"
      ],
      "metadata": {
        "id": "D4_ziC688rLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up parameters\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = 2\n",
        "max_length = 128\n",
        "batch_size = 16\n",
        "num_epochs = 4\n",
        "learning_rate = 2e-5"
      ],
      "metadata": {
        "id": "_1zrf9Lfm6H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **load and splitting the dataset**"
      ],
      "metadata": {
        "id": "GCq_vGIS9h43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HaTgDvVBm6KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize tokenizer, dataset, and data loader**"
      ],
      "metadata": {
        "id": "cb1xLiFl9slx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "mmFfC3XIm6MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **setup the device and model**\n"
      ],
      "metadata": {
        "id": "Tb1Or4bX92p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BERTClassifier(bert_model_name, num_classes).to(device)"
      ],
      "metadata": {
        "id": "VAt20iB6m6Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set up optimizer and learning rate scheduler**"
      ],
      "metadata": {
        "id": "QS1W_-6c-Dfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "86NUjyOOm6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad4ba0c-2e6a-4ae2-c8e8-0427f909059d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the model**\n"
      ],
      "metadata": {
        "id": "YVDjccbR-L8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "  train(model, train_dataloader, optimizer, scheduler, device)\n",
        "  accuracy, report = evaluate(model, val_dataloader, device)\n",
        "  print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "  print(report)"
      ],
      "metadata": {
        "id": "ad5oxYP1m6U4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976c31ad-c1f8-485c-d212-b7b294e118fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "Validation Accuracy: 0.8930\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89      4961\n",
            "           1       0.91      0.88      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Epoch 2/4\n",
            "Validation Accuracy: 0.8922\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      4961\n",
            "           1       0.92      0.86      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Epoch 3/4\n",
            "Validation Accuracy: 0.8960\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90      4961\n",
            "           1       0.90      0.90      0.90      5039\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "Epoch 4/4\n",
            "Validation Accuracy: 0.8952\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89      4961\n",
            "           1       0.90      0.89      0.90      5039\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the train model**"
      ],
      "metadata": {
        "id": "vBGmIZ7q-Qmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"my_bert_classifier.pth\")"
      ],
      "metadata": {
        "id": "Yuozck6Sm6Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating our model performance**"
      ],
      "metadata": {
        "id": "0Hu8Pceu-Xo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"The movie was great and I really enjoyed the performances of the actors.\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"The movie was great and I really enjoyed the performances of the actors.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "id": "M4U2im9Qm6aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccd2510-c1dd-4f9f-b753-3fbfc175079f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie was great and I really enjoyed the performances of the actors.\n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"The movie was so bad and I would not recommend it to anyone.\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"The movie was so bad and I would not recommend it to anyone.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "id": "Pld2CCg2m6dA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea12316-614e-4f4d-e3dc-17eb143ec4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie was so bad and I would not recommend it to anyone.\n",
            "Predicted sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"Worst movie of the year.\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"Worst movie of the year.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyFsDvy9-l9g",
        "outputId": "06aa565f-b0e5-4ec3-fd85-7c3dada44b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worst movie of the year.\n",
            "Predicted sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"The movie was very intersting\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"Worst movie of the year.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc6ilTcV6Alz",
        "outputId": "39f31288-33a6-4769-921d-83d2711c4f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worst movie of the year.\n",
            "Predicted sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTLeZ4mO6MkD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}